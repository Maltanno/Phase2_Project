{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import cross_val_score as CVS\n",
    "from sklearn.preprocessing import PolynomialFeatures as PF\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.tools.eval_measures import rmse as RMSE\n",
    "import scipy.stats as stats\n",
    "import numbers\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data_t, poly=None, test=False):\n",
    "    \"\"\"\n",
    "    poly values: 'all', 'list', 'singles', 'all_single'\n",
    "    Note: singles/all_single -column names only have first letters\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #     'bathroomsx4', 'bedrooms', 'condition', 'date', 'floorsx2', 'grade', 'lat',\n",
    "#        'long', 'price', 'sqft_above', 'sqft_basement', 'sqft_living',\n",
    "#         'sqft_living15', 'sqft_lot', 'sqft_lot15', 'view', 'waterfront',\n",
    "#         'yr_built', 'yr_renovated', 'zipcode'\n",
    "    \n",
    "    to_poly = ['sqft_above', 'sqft_basement', 'sqft_living',\n",
    "              'sqft_living15', 'sqft_lot', 'sqft_lot15','yr_built', \n",
    "              'yr_renovated',]\n",
    "    to_log = ['price', 'sqft_above', 'sqft_basement', 'sqft_living',\n",
    "              'sqft_living15', 'sqft_lot', 'sqft_lot15','yr_built', \n",
    "              'yr_renovated',]\n",
    "    to_norm = []#['price', 'sqft_above', 'sqft_basement', 'sqft_living',\n",
    "#               'sqft_living15', 'sqft_lot', 'sqft_lot15','yr_built', \n",
    "#               'yr_renovated',]\n",
    "    to_ohe = ['bedrooms', 'bathroomsx4','condition', 'floorsx2','grade','view',]\n",
    "    poly_order = 2\n",
    "\n",
    "    if poly in ['all', 'all_single']:\n",
    "        to_poly = data_t.drop(to_ohe + ['price'], axis=1).columns\n",
    "        if poly == 'all':\n",
    "            poly = 'list'\n",
    "        elif poly == 'all_single':\n",
    "            poly = 'singles'\n",
    "    if poly == 'list':\n",
    "        poly=PF(poly_order)\n",
    "        data_poly = poly.fit_transform(data_t[to_poly])\n",
    "        data_poly = pd.DataFrame(data_poly)\n",
    "        data_poly.columns = poly.get_feature_names(data_t[to_poly].columns)\n",
    "        data_t = pd.concat([data_t.drop(to_poly, axis=1),\n",
    "                            data_poly.drop('1',axis=1)], axis=1)\n",
    "    elif poly == 'singles':\n",
    "        for feat in to_poly:\n",
    "            df = pd.DataFrame(data_t[feat])\n",
    "            print(feat)\n",
    "            poly=PF(poly_order)\n",
    "            data_poly = poly.fit_transform(df)\n",
    "            data_poly = pd.DataFrame(data_poly)\n",
    "            data_poly.columns = ['drop', feat, feat + '_squared']\n",
    "            data_t = pd.concat([data_t.drop(feat, axis=1), \n",
    "                                data_poly.drop('drop',axis=1)], axis=1)\n",
    "\n",
    "    for feat in to_log:\n",
    "        data_t[feat] = data_t[feat].map(lambda x: np.log(x) if x!=0 else 0)\n",
    "        #Note 'if' included so that 0 values wouldn't error, will still error\n",
    "        #...between 0 and 1. Also, implies that the original 0 value was a 1\n",
    "        #...but as these are around values of 100s, 1000s, the effect is minimal\n",
    "\n",
    "        \n",
    "    stats = {}\n",
    "    if test:\n",
    "        with open('norm_stats.pickle', 'rb') as f:\n",
    "            stats = pickle.load(f)\n",
    "    for feat in to_norm:\n",
    "        ft = data_t[feat]\n",
    "        if test:\n",
    "            mean = stats[feat][0]\n",
    "            stdev = stats[feat][1]\n",
    "        else:\n",
    "            mean = np.mean(ft)\n",
    "            stdev = np.sqrt(np.var(ft))\n",
    "        data_t[feat] = (ft-mean) / stdev\n",
    "        stats[feat] = [mean, stdev]\n",
    "    with open('norm_stats.pickle', 'wb') as f:\n",
    "        pickle.dump(stats, f)\n",
    "        \n",
    "        \n",
    "    for feat in to_ohe:\n",
    "        dummies = pd.get_dummies(data=data_t[feat], prefix=feat, prefix_sep='_',\n",
    "                                drop_first=True)\n",
    "        data_t.drop(feat, axis=1, inplace=True)\n",
    "        data_t = pd.concat([data_t, dummies], axis=1)\n",
    "    data_t.rename(lambda col: col.replace('.0', '').replace(' ','__')\n",
    "                  .replace('^','_pow_'),\n",
    "                  axis=1, inplace=True)\n",
    "    \n",
    "    return data_t \n",
    "\n",
    "#Note data_t = data.copy()   --line added as otherwise the DataFrame, data, \n",
    "#...outside of this function lost the first column mentioned in [to_ohe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_selector(data_s, x_cols, alpha=0.05):\n",
    "\n",
    "    predictors = '+'.join(x_cols)\n",
    "    f = 'price' + '~' + predictors\n",
    "    results = ols(formula=f, data=data_s).fit()\n",
    "    pv = pd.DataFrame(results.pvalues).drop('Intercept')\n",
    "    pv.rename(columns={0:'p_value'}, inplace=True)\n",
    "    x_cols = list(pv[pv.p_value <= alpha].index)\n",
    "    \n",
    "    return x_cols, pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_selector(data_s, \n",
    "                       x_cols=[], \n",
    "                       alpha=0.05, \n",
    "                       verbose=False):\n",
    "    \"\"\" \n",
    "    Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        x_cols - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    \n",
    "    X = data_s[x_cols]\n",
    "    y = data_s['price']\n",
    "    threshold_in = alpha - 0.02\n",
    "    threshold_out = alpha + 0.01\n",
    "    included = list(x_cols)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            results = sm.OLS(y, sm.add_constant\n",
    "                             (pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = results.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        results = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = results.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, \n",
    "                                                             worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "            \n",
    "    pv = pd.DataFrame(results.pvalues)\n",
    "    pv.rename(columns={0:'p_value'}, inplace=True)\n",
    "    return included, pv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicollinearity Function: Remove    \n",
    "The first multicollinearity function removes a feature from each pair with high multicollinearity    \n",
    "This function takes in thedata, x_cols and the threshold for removing a feature\n",
    "\n",
    "- create a dataframe of the correlation of the features in x_cols   \n",
    "- transform this to get a list of pairs of features with high multicollinearity\n",
    "- for each pair: check whether they are the same feature or if one of the features has already been listed to be removed; if so, continue to next pair \n",
    "- otherwise add the feature with the higher p-value to a list    \n",
    "- remove the features in this list from x_cols    \n",
    "\n",
    "\n",
    "return x_cols     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multicoll_remove(data, x_cols, pvalues, multicollinearity_threshold):\n",
    "    corr = data[x_cols].corr().abs().stack().reset_index().sort_values(0,\n",
    "                                                            ascending = False)\n",
    "    corr['pairs'] = list(zip(corr.level_0, corr.level_1))\n",
    "    corr = corr.set_index('pairs').drop(['level_0', 'level_1'], axis=1)\n",
    "    corr.columns = ['cc']\n",
    "    corr = corr[corr.cc > multicollinearity_threshold]        \n",
    "\n",
    "    to_drop = []\n",
    "    for f0, f1 in corr.index:\n",
    "        if (f0 == f1) | any(feat in [f0, f1] for feat in to_drop):\n",
    "            continue\n",
    "        to_drop.append(pvalues.loc[[f0, f1]].sort_values('p_value', \n",
    "                                                ascending=False).index[0])\n",
    "    x_cols = list(set(x_cols) - set(to_drop))\n",
    "    return x_cols   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(data_m, results, x_cols):\n",
    "#     X = data[x_cols]\n",
    "#     y = data.price\n",
    "#     to_pred = pd.concat([y,X], axis=1)\n",
    "#     yhat = results.predict(to_pred)\n",
    "#     rmse = RMSE(y, yhat)\n",
    "    \n",
    "#     linreg = LR()\n",
    "#     linreg.fit(X,y)\n",
    "#     cv  = np.mean(CVS(linreg, X, y, cv=5,  scoring='neg_mean_squared_error'))\n",
    "#     rmse = (-cv)**0.5\n",
    "      \n",
    "#     print(f'RMSE: {rmse}')\n",
    "    \n",
    "    fig = sm.graphics.qqplot(results.resid, dist=stats.norm, line='45',\n",
    "                             fit=True, alpha=0.1)\n",
    "\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    plt.scatter(data_m.price, results.resid, alpha=0.5);\n",
    "    plt.hlines(0, xmax=data_m.price.max(), xmin=data_m.price.min());    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Function\n",
    "Takes in the dataframe and optional transform and multicollinearity arguments    \n",
    "Checks whether to send the data to a transform function   \n",
    "Selects for x_cols the features from data that are numeric, and not the price   \n",
    "##### Loop\n",
    "\n",
    "**1. Remove features with high p-values:**  \n",
    "- creates the formula using x_cols     \n",
    "- creates the model using formula   \n",
    "- creates a dataframe, pv, of the model's p-values  \n",
    "- creates a new x_cols list from the features in pv with low p-values   \n",
    "\n",
    "**2. Handle multicollinearity:**     \n",
    "- Checks whether a function has been passed for handling multicollinearity and calls accordingly    \n",
    "    \n",
    "         \n",
    "            \n",
    "            \n",
    "Checks whether the length of x_cols has changed. Loop runs again if it has.     \n",
    "    \n",
    "    \n",
    "When x_cols no longer changes, the final model and x_cols are returned\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling(datam, selector=simple_selector, transform=None, multicoll=None, \n",
    "              alpha=0.05, \n",
    "              multicollinearity_threshold = 0.7):\n",
    "    \n",
    "    if transform:\n",
    "        datam = transform(datam)\n",
    "        \n",
    "    outcome = 'price'\n",
    "    x_cols = [col for col in (datam.drop([outcome], axis=1).columns) \n",
    "            if isinstance(datam[col][0], numbers.Number)]\n",
    "    i = 0\n",
    "    while True:\n",
    "        length0 = len(x_cols)\n",
    "        print(f'Loop:{i}\\nNumber of features: {length0}')\n",
    "        \n",
    "        x_cols, pvalues = selector(datam, x_cols, alpha)\n",
    "        length1 = length0-len(x_cols)\n",
    "        print(f'Removed by Selector: {length1}')\n",
    "        \n",
    "        if not i and multicoll:\n",
    "            x_cols = multicoll(datam, x_cols, pvalues, \n",
    "                                      multicollinearity_threshold)\n",
    "            length2 = length0 - length1 - len(x_cols)\n",
    "            print(f'Removed for multicollinearity: {length2}')\n",
    "        \n",
    "        \n",
    "        i+=1\n",
    "        if len(x_cols) == length0:\n",
    "            break\n",
    "        \n",
    "    predictors = '+'.join(x_cols)\n",
    "    f = 'price' + '~' + predictors\n",
    "    results = ols(formula=f, data=datam).fit()\n",
    "\n",
    "    metrics(datam, results, x_cols)\n",
    "    \n",
    "    return results, x_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial model using only cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2014-10-01'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-54c5f8aef47a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdata_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoly\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0moutcome\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'price'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-a884af997098>\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(data_t, poly, test)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpoly\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'list'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mpoly\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoly_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mdata_poly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mto_poly\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mdata_poly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_poly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mdata_poly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mto_poly\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1463\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m         \"\"\"\n\u001b[1;32m-> 1465\u001b[1;33m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1466\u001b[0m         combinations = self._combinations(n_features, self.degree,\n\u001b[0;32m   1467\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteraction_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2014-10-01'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/clean.csv')\n",
    "#data = data[data.price < 2000000]\n",
    "\n",
    "data.sort_index(axis=1, inplace=True)\n",
    "data_train, data_test = tts(data, train_size=0.8, random_state=111)\n",
    "data_train = data_train.reset_index().drop('index', axis=1)\n",
    "\n",
    "multicollinearity_threshold=0.7\n",
    "alpha=0.05\n",
    "\n",
    "\n",
    "data_t = transform(data_train, poly='all')\n",
    "\n",
    "outcome = 'price'\n",
    "x_cols = [col for col in (data_t.drop([outcome], axis=1).columns) \n",
    "                    if isinstance(data_t[col][0], numbers.Number)]\n",
    "\n",
    "x_cols, pvalues = stepwise_selector(data_t, x_cols, alpha=alpha)\n",
    "\n",
    "x_cols = multicoll_remove(data_t, x_cols, pvalues, multicollinearity_threshold)\n",
    "x_cols, pvalues = stepwise_selector(data_t, x_cols)\n",
    "\n",
    "predictors = '+'.join(x_cols)\n",
    "f = 'price' + '~' + predictors\n",
    "results = ols(formula=f, data=data_t).fit()\n",
    "\n",
    "metrics(data_t, results, x_cols)\n",
    "results.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sm.graphics.qqplot(results.resid, dist=stats.norm, line='45',\n",
    "                         fit=True, alpha=0.1)\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "plt.scatter(data.price, results.resid, alpha=0.5);\n",
    "plt.hlines(0, xmax=data.price.max(), xmin=data.price.min());    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathroomsx4</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>condition</th>\n",
       "      <th>date</th>\n",
       "      <th>floorsx2</th>\n",
       "      <th>grade</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>price</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>view</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>47.6170</td>\n",
       "      <td>-122.288</td>\n",
       "      <td>1330000.0</td>\n",
       "      <td>2080</td>\n",
       "      <td>280</td>\n",
       "      <td>2360</td>\n",
       "      <td>2840</td>\n",
       "      <td>5504</td>\n",
       "      <td>5470</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1913</td>\n",
       "      <td>1913</td>\n",
       "      <td>98122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-08-27</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>47.6518</td>\n",
       "      <td>-122.160</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>2950</td>\n",
       "      <td>1400</td>\n",
       "      <td>4350</td>\n",
       "      <td>3280</td>\n",
       "      <td>37169</td>\n",
       "      <td>41631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1972</td>\n",
       "      <td>1972</td>\n",
       "      <td>98005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-06-12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>47.6415</td>\n",
       "      <td>-122.303</td>\n",
       "      <td>620000.0</td>\n",
       "      <td>1300</td>\n",
       "      <td>130</td>\n",
       "      <td>1430</td>\n",
       "      <td>1750</td>\n",
       "      <td>3000</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>98112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>47.3410</td>\n",
       "      <td>-122.179</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>2544</td>\n",
       "      <td>0</td>\n",
       "      <td>2544</td>\n",
       "      <td>2358</td>\n",
       "      <td>4071</td>\n",
       "      <td>4179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>98030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-04-29</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>47.6972</td>\n",
       "      <td>-122.025</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>1290</td>\n",
       "      <td>0</td>\n",
       "      <td>1290</td>\n",
       "      <td>1290</td>\n",
       "      <td>2482</td>\n",
       "      <td>2482</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>98053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16982</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>47.6757</td>\n",
       "      <td>-122.309</td>\n",
       "      <td>678940.0</td>\n",
       "      <td>1750</td>\n",
       "      <td>860</td>\n",
       "      <td>2610</td>\n",
       "      <td>2160</td>\n",
       "      <td>4080</td>\n",
       "      <td>4080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1909</td>\n",
       "      <td>1909</td>\n",
       "      <td>98115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16983</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-05-16</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>47.5458</td>\n",
       "      <td>-121.996</td>\n",
       "      <td>619500.0</td>\n",
       "      <td>2170</td>\n",
       "      <td>0</td>\n",
       "      <td>2170</td>\n",
       "      <td>2170</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>98029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16984</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-04-22</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>47.4729</td>\n",
       "      <td>-122.301</td>\n",
       "      <td>278000.0</td>\n",
       "      <td>1120</td>\n",
       "      <td>780</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>9994</td>\n",
       "      <td>9994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1960</td>\n",
       "      <td>1960</td>\n",
       "      <td>98168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16985</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-11-18</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>47.5598</td>\n",
       "      <td>-122.018</td>\n",
       "      <td>645500.0</td>\n",
       "      <td>2390</td>\n",
       "      <td>0</td>\n",
       "      <td>2390</td>\n",
       "      <td>2630</td>\n",
       "      <td>9638</td>\n",
       "      <td>9258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1988</td>\n",
       "      <td>1988</td>\n",
       "      <td>98029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16986</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-08-26</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>47.6988</td>\n",
       "      <td>-121.915</td>\n",
       "      <td>420000.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1850</td>\n",
       "      <td>21010</td>\n",
       "      <td>18151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>98014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16987 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bathroomsx4  bedrooms  condition        date  floorsx2  grade      lat  \\\n",
       "0                9         3          4  2014-10-01         4      8  47.6170   \n",
       "1               12         5          3  2014-08-27         4     10  47.6518   \n",
       "2                4         2          3  2014-06-12         3      7  47.6415   \n",
       "3               10         4          3  2015-03-31         4      9  47.3410   \n",
       "4                4         2          3  2015-04-29         4      7  47.6972   \n",
       "...            ...       ...        ...         ...       ...    ...      ...   \n",
       "16982            9         5          5  2014-12-09         4      7  47.6757   \n",
       "16983           10         3          3  2014-05-16         4      9  47.5458   \n",
       "16984            6         3          3  2015-04-22         2      7  47.4729   \n",
       "16985           10         4          3  2014-11-18         4     10  47.5598   \n",
       "16986            9         3          3  2014-08-26         4      7  47.6988   \n",
       "\n",
       "          long      price  sqft_above  sqft_basement  sqft_living  \\\n",
       "0     -122.288  1330000.0        2080            280         2360   \n",
       "1     -122.160   900000.0        2950           1400         4350   \n",
       "2     -122.303   620000.0        1300            130         1430   \n",
       "3     -122.179   415000.0        2544              0         2544   \n",
       "4     -122.025   300000.0        1290              0         1290   \n",
       "...        ...        ...         ...            ...          ...   \n",
       "16982 -122.309   678940.0        1750            860         2610   \n",
       "16983 -121.996   619500.0        2170              0         2170   \n",
       "16984 -122.301   278000.0        1120            780         1900   \n",
       "16985 -122.018   645500.0        2390              0         2390   \n",
       "16986 -121.915   420000.0        2020              0         2020   \n",
       "\n",
       "       sqft_living15  sqft_lot  sqft_lot15  view  waterfront  yr_built  \\\n",
       "0               2840      5504        5470     0           0      1913   \n",
       "1               3280     37169       41631     0           0      1972   \n",
       "2               1750      3000        4000     0           0      1929   \n",
       "3               2358      4071        4179     0           0      2013   \n",
       "4               1290      2482        2482     0           0      2008   \n",
       "...              ...       ...         ...   ...         ...       ...   \n",
       "16982           2160      4080        4080     0           0      1909   \n",
       "16983           2170      5000        5000     0           0      2003   \n",
       "16984           1900      9994        9994     0           0      1960   \n",
       "16985           2630      9638        9258     0           0      1988   \n",
       "16986           1850     21010       18151     0           0      1995   \n",
       "\n",
       "       yr_renovated  zipcode  \n",
       "0              1913    98122  \n",
       "1              1972    98005  \n",
       "2              1929    98112  \n",
       "3              2013    98030  \n",
       "4              2008    98053  \n",
       "...             ...      ...  \n",
       "16982          1909    98115  \n",
       "16983          2003    98029  \n",
       "16984          1960    98168  \n",
       "16985          1988    98029  \n",
       "16986          1995    98014  \n",
       "\n",
       "[16987 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/clean.csv')\n",
    "#data = data[data.price < 2000000]\n",
    "\n",
    "data.sort_index(axis=1, inplace=True)\n",
    "data_train, data_test = tts(data, train_size=0.8, random_state=111)\n",
    "multicollinearity_threshold=0.7\n",
    "\n",
    "#data_t = data.copy()\n",
    "# data_t = transform(data_train)\n",
    "data_train = data_train.reset_index().drop('index', axis=1)\n",
    "data_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
